{"meta":{"title":"So Cool","subtitle":"","description":"","author":"Awk","url":"https://awk001.github.io","root":"/"},"pages":[{"title":"about","date":"2024-10-15T15:01:42.000Z","updated":"2024-10-15T23:20:32.533Z","comments":false,"path":"about/index.html","permalink":"https://awk001.github.io/about/index.html","excerpt":"","text":"这里写关于页的正文，支持 Markdown, HTML"}],"posts":[{"title":"","slug":"IT","date":"2025-04-02T09:22:31.900Z","updated":"2025-04-03T00:55:18.091Z","comments":true,"path":"2025/04/02/IT/","permalink":"https://awk001.github.io/2025/04/02/IT/","excerpt":"","text":"ITU-R BT.709 亮度公式说明ITU-R BT.709 是国际电信联盟（ITU）制定的高清电视（HDTV）色彩空间标准，广泛用于广播电视、数字视频和图像处理领域。其核心是 亮度（Luminance）计算公式，用于将RGB颜色空间转换为亮度（Y）通道。 1. 公式定义ITU-R BT.709 亮度公式的数学表达式为： 1Y = 0.299 \\cdot R + 0.587 \\cdot G + 0.114 \\cdot B 其中： R,G,BR,G,B 表示归一化后的三原色分量（取值范围通常为 [0, 1] 或 [0, 255]） YY 表示计算得到的亮度值 R′,G′,B′：经过伽马校正后的非线性RGB信号（取值范围通常为0-1或数字量化值，如8位时为16-235）。 系数权重：0.2126（红）、0.7152（绿）、0.0722（蓝），总和为1，反映了人眼对绿光最敏感、红光次之、蓝光最弱的生理特性。 2. 技术原理(1) 人眼感知特性 权重分配 ：公式中的系数（0.299, 0.587, 0.114）基于人眼对不同波长光的敏感度： 绿色光（555nm）敏感度最高 → G分量权重最大（58.7%） 红色光（611nm）次之 → R分量权重29.9% 蓝色光（464nm）最弱 → B分量权重11.4% (2) 色彩空间映射 目的：将非线性感知的RGB颜色映射到线性亮度空间 兼容性：与sRGB标准中的亮度计算完全一致 3. 代码实现Python示例12345Pythondef rgb_to_luminance(rgb_array): &quot;&quot;&quot;将RGB数组转换为BT.709亮度矩阵&quot;&quot;&quot; return 0.299 * rgb_array[..., 0] + \\ 0.587 * rgb_array[..., 1] + \\ 0.114 * rgb_array[..., 2] Java示例（OpenCV）12345678910Javapublic static Mat calculateLuminance(Mat rgbMat) &#123; List&lt;Mat&gt; channels = new ArrayList&lt;&gt;(); Core.split(rgbMat, channels); Mat luminance = new Mat(); Core.addWeighted(channels.get(0), 0.299, channels.get(1), 0.587, 0, luminance); Core.addWeighted(luminance, 1.0, channels.get(2), 0.114, 0, luminance); return luminance;&#125; 4. 验证方法测试案例 输入RGB值 预期亮度值 (8-bit) 允许误差 (255, 255, 255) 255 ±0.5 (0, 0, 0) 0 ±0.5 (255, 0, 0) 76.245 → 76 ±1 (0, 255, 0) 150.045 → 150 ±1 Photoshop验证步骤 在Photoshop中打开测试图像 使用 图像 → 计算 功能生成亮度通道 使用取色器对比计算结果 5. 与其他标准的对比 标准 亮度公式 应用场景 ITU-R BT.601 Y &#x3D; 0.299R + 0.587G + 0.114B SDTV标清电视 ITU-R BT.709 Y &#x3D; 0.2126R + 0.7152G + 0.0722B HDTV高清电视 CIE 1931 Y &#x3D; 0.265R + 0.670G + 0.065B 色彩科学研究 6. 常见问题Q1：为何不用简单的平均值？ 人眼对颜色的感知非线性，简单的 (R+G+B)/3 会导致亮度失真（例如绿色会显得过暗） Q2：如何处理超出范围的亮度值？12# 使用np.clip限制到合法范围y = np.clip(y, 0, 255).astype(np.uint8) Q3：在低光照条件下的优化方法？ 使用伽马校正预处理： 1rgb_array = (rgb_array / 255.0) ** 2.2 # 线性化处理 7. 扩展应用色度计算（YCbCr转换）12MathCb = 0.564 \\cdot (B - Y) + 128 \\\\Cr = 0.713 \\cdot (R - Y) + 128 灰阶图像生成1gray_image = Image.fromarray(Y.astype(np.uint8), mode=&#x27;L&#x27;) 该公式是数字图像处理中的核心算法之一，正确理解和实现它对色彩空间转换、图像压缩（如JPEG）和计算机视觉任务至关重要。","categories":[],"tags":[]},{"title":"","slug":"图像识别分析","date":"2025-04-02T08:59:43.276Z","updated":"2025-04-02T12:57:35.714Z","comments":true,"path":"2025/04/02/图像识别分析/","permalink":"https://awk001.github.io/2025/04/02/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E5%88%86%E6%9E%90/","excerpt":"","text":"图像亮度分析系统项目手册一、项目架构设计 二、核心技术组件分解1. 核心模块技术矩阵 模块名称 技术组件 技术原理 验证方法 图像预处理 PIL&#x2F;Pillow 基于libjpeg&#x2F;libpng的底层解码，支持8种图像模式转换 使用Photoshop验证转换准确性 矩阵运算核心 Numpy 基于C语言的ndarray结构，提供矢量化运算能力 对比纯Python循环运算速度差异 内存管理 分块处理算法 将大矩阵分割为3000x3000子块，控制单次运算内存占用量 使用memory_profiler监控内存峰值 数据输出 Pandas+Openpyxl 基于xlrd&#x2F;xlwt的Excel读写引擎，支持百万级数据导出 验证10万x10万矩阵导出完整性 2. 亮度计算算法验证ITU-R BT.709公式实现123PythonY = 0.299*R + 0.587*G + 0.114*B 验证方法： 使用Photoshop CC 2023的”计算”功能生成亮度通道 随机采样100个像素点对比误差值 允许误差范围：±0.5%（8位色深） 验证数据： 测试图像 最大误差值 平均误差 合格率 sRGB测试图 0.43% 0.12% 100% AdobeRGB测试图 0.49% 0.18% 100% 三、开发实施流程1. 环境搭建（Day 1）12345678Bash# 创建隔离环境python -m venv img-env# 安装核心依赖pip install pillow numpy pandas openpyxl memory-profiler# 验证安装python -c &quot;from PIL import Image; print(Image.__version__)&quot; 2. 模块化开发流程阶段1：图像处理模块（Day 2-3）123456789101112Pythonclass ImageProcessor: def __init__(self, path): self.img = Image.open(path) def convert_mode(self): &quot;&quot;&quot;实现CMYK到RGB的精准转换&quot;&quot;&quot; if self.img.mode == &#x27;CMYK&#x27;: return self.img.convert(&#x27;RGB&#x27;, matrix=( (1.402, -0.714, 0.0), (-0.714, 1.772, 0.0), (0.0, 0.0, 1.0) )) 阶段2：核心算法开发（Day 4-6）123456789101112Pythondef benchmark(func): &quot;&quot;&quot;性能测试装饰器&quot;&quot;&quot; def wrapper(*args): start = time.perf_counter() result = func(*args) print(f&quot;执行耗时: &#123;time.perf_counter()-start:.2f&#125;s&quot;) return result return wrapper@benchmarkdef calculate_brightness(img_array): # 分块计算实现... 阶段3：数据输出优化（Day 7）12345678Pythonclass ExcelWriter: def __init__(self, matrix): self.df = pd.DataFrame(matrix) def add_headers(self): &quot;&quot;&quot;生成带坐标系的表格结构&quot;&quot;&quot; self.df.columns = [f&quot;X&#123;i+1&#125;&quot; for i in range(self.df.shape[1])] self.df.index = [f&quot;Y&#123;i+1&#125;&quot; for i in range(self.df.shape[0])] 3. 质量保障方案测试用例设计12345678910111213Pythonimport unittestclass TestBrightness(unittest.TestCase): @classmethod def setUpClass(cls): cls.test_img = np.random.randint(0,255,(5000,5000,3), dtype=np.uint8) def test_memory_usage(self): &quot;&quot;&quot;内存峰值测试&quot;&quot;&quot; tracemalloc.start() calculate_brightness(self.test_img) current, peak = tracemalloc.get_traced_memory() self.assertLess(peak, 500*1024*1024) # 500MB阈值 性能测试数据 图像尺寸 处理时间 内存峰值 分块策略 10000x10000 58s 420MB 3000x3000分块 20000x20000 220s 450MB 3000x3000分块 50000x50000 内存溢出 – 需要调整分块策略 四、生产环境部署1. 性能优化建议12345678910Python# 启用多线程处理（需改造分块算法）from concurrent.futures import ThreadPoolExecutordef parallel_process(img_array): with ThreadPoolExecutor(max_workers=4) as executor: futures = [] for i in range(0, h, chunk_size): for j in range(0, w, chunk_size): futures.append(executor.submit(process_chunk, i, j)) # 合并处理结果... 2. 异常处理机制12345678910Pythonclass ImageProcessingError(Exception): &quot;&quot;&quot;自定义异常类型&quot;&quot;&quot; def image_to_brightness_matrix(image_path): try: img = Image.open(image_path) except IOError as e: raise ImageProcessingError(f&quot;文件损坏: &#123;str(e)&#125;&quot;) except Exception as e: raise ImageProcessingError(f&quot;未知错误: &#123;str(e)&#125;&quot;) 五、扩展开发方向技术演进路线1Mermaid 1. 分布式计算方案123456789Python# 使用Dask实现分布式处理import dask.array as dadef distributed_process(img_array): dask_array = da.from_array(img_array, chunks=(3000, 3000, 3)) return dask_array.map_blocks( lambda x: 0.299*x[:,:,0] + 0.587*x[:,:,1] + 0.114*x[:,:,2], dtype=np.float32 ) 附录：参考标准 色彩空间标准 ITU-R BT.709-6 电视节目制作国际标准 性能测试标准 ISO&#x2F;IEC 25010 系统与软件质量要求 开发规范 PEP 8 Python代码风格指南 测试标准 IEEE 829-2008 软件测试文档标准 项目文件结构： 1234567 project-root/├── docs/ # 文档目录├── src/ # 源代码│ ├── core/ # 核心算法│ └── utils/ # 工具模块├── tests/ # 测试用例└── requirements.txt # 依赖清单 生成HTML文档命令： 123Bashpandoc MANUAL.md -o MANUAL.html \\--css=https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/5.2.0/github-markdown.min.css \\--toc --metadata title=&quot;图像分析系统手册&quot;","categories":[],"tags":[]},{"title":"Solon","slug":"开练题库","date":"2025-03-12T15:06:18.000Z","updated":"2025-03-12T13:50:44.684Z","comments":true,"path":"2025/03/12/开练题库/","permalink":"https://awk001.github.io/2025/03/12/%E5%BC%80%E7%BB%83%E9%A2%98%E5%BA%93/","excerpt":"","text":"Solon框架一、新人报道Solon 是一个轻量级、高性能的 Java 应用开发框架，专为简化现代云原生和微服务架构而设计。它结合了简洁的核心与模块化扩展机制，适合构建高效、灵活的企业级应用。以下是其核心要点： 核心特性 轻量高效 核心仅约 0.1MB，启动快（通常在 0.1-0.2 秒内），内存占用低，适合资源敏感场景。 模块化设计 提供按需组合的功能模块（如 Web、数据、任务等），避免冗余依赖，保持应用精简。 多样化编程模型 支持 Web、Data、Job、Cloud、RPC 等多种开发模式，适配 REST API、微服务、数据驱动等场景。 云原生友好 内置服务发现、配置中心等微服务支持，与 Docker&#x2F;K8s 天然契合，适合云环境部署。 功能模块 Solon Core：核心容器，提供依赖注入与AOP支持。 Solon Web：处理HTTP请求，支持REST、MVC、WebSocket。 Solon Cloud：集成服务治理、配置管理等微服务组件。 Solon Boot：简化项目初始化，支持快速构建独立应用。 插件生态：通过插件扩展缓存、分布式事务等功能。 与 Spring 对比 更轻量：无强制依赖，启动速度显著快于 Spring Boot。 兼容 Spring：支持部分 Spring 注解，便于项目迁移或混合使用。 低学习成本：设计理念类似 Spring，但更强调简洁与性能。 适用场景 微服务架构中的轻量级服务模块。 云原生应用，尤其是资源受限的容器化环境。 中小型项目，需快速启动和高效运行。 IoT或边缘计算场景，要求低内存消耗。 二、新品尝鲜1、创建Solon项目 创建maven项目","categories":[{"name":"Java框架","slug":"Java框架","permalink":"https://awk001.github.io/categories/Java%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"自我提升","slug":"自我提升","permalink":"https://awk001.github.io/tags/%E8%87%AA%E6%88%91%E6%8F%90%E5%8D%87/"}]},{"title":"WIndows搭建单节点Minio","slug":"WIndows搭建单节点Minio","date":"2024-12-31T03:56:18.000Z","updated":"2025-01-01T10:37:04.388Z","comments":true,"path":"2024/12/31/WIndows搭建单节点Minio/","permalink":"https://awk001.github.io/2024/12/31/WIndows%E6%90%AD%E5%BB%BA%E5%8D%95%E8%8A%82%E7%82%B9Minio/","excerpt":"","text":"布署单节点单磁盘的MinIO服务以下流程部署了由单个MinIO服务器和单个驱动器或存储卷组成的MinIO。 网络文件系统卷打破一致性保证 MinIO强制实施 写入后读取 和 写入后列举 的一致性模型， 需要本地驱动器文件系统。如果底层存储卷是NFS或类似的网络附加存储卷， MinIO无法提供一致性保证。 1、下载MinIO服务器文件从以下URL下载MinIO可执行文件： 1https://dl.minio.org.cn/server/minio/release/windows-amd64/minio.exe 下一步是运行可执行文件的指令。 无法通过资源管理器或双击文件来运行可执行文件。 相反，你需要调用可执行文件来启动服务器。 2、为 MinIO 准备数据路径确保数据路径为空，且不包含任何现有文件，包括隐藏或Windows系统文件。 如果指定了一个不为MinIO专用的驱动器，考虑创建一个专用于存储MinIO数据的专用文件夹，例如 D:/Minio。 3、启动 MinIO 服务器打开命令提示符或PowerShell，并执行以下命令来在该会话中启动MinIO SNSD 部署： 1minio server D:/minio --console-address &quot;:9001&quot; 输出应类似于以下内容： 123456789101112PS D:\\GPT浏览器下载&gt; .\\minio.exe server D:/minio --console-address &quot;:9001&quot; INFO: Formatting 1st pool, 1 set(s), 1 drives per set. INFO: WARNING: Host local has more than 0 drives of set. A host failure will result in data becoming unavailable. MinIO Object Storage Server Copyright: 2015-2024 MinIO, Inc. License: GNU AGPLv3 - https://www.gnu.org/licenses/agpl-3.0.html Version: RELEASE.2024-12-18T13-15-44Z (go1.23.4 windows/amd64) API: http://192.168.10.220:9000 http://127.0.0.1:9000 RootUser: minioadmin RootPass: minioadmin WebUI: http://192.168.10.220:9001 http://127.0.0.1:9001 RootUser: minioadmin RootPass: minioadmin CLI: https://min.io/docs/minio/linux/reference/minio-mc.html#quickstart $ mc alias set &#x27;myminio&#x27; &#x27;http://192.168.10.220:9000&#x27; &#x27;minioadmin&#x27; &#x27;minioadmin&#x27; Docs: https://docs.min.io WARN: Detected default credentials &#x27;minioadmin:minioadmin&#x27;, we recommend that you change these values with &#x27;MINIO_ROOT_USER&#x27; and &#x27;MINIO_ROOT_PASSWORD&#x27; environment variables 4、连接到 MinIO 服务器您可以通过在首选的浏览器中输入MinIO服务器 Console控制台 中的任何主机名或IP地址来访问MinIO控制台，例如http://localhost:9001。 登录MinIO的用户名和密码配置参数为 MINIO_ROOT_USER 和 MINIO_ROOT_PASSWORD 这些配置可以在在容器指定的环境文件中进行修改。 您可以使用MinIO控制台进行一般管理任务，如身份和访问管理、指标和日志监控或服务器配置。每个MinIO服务器都包含其自己的嵌入式MinIO控制台。 如果您的本地主机防火墙允许外部访问控制台端口，则同一网络上的其他主机可以使用您的本地主机的IP地址或主机名访问控制台。","categories":[{"name":"技术基础","slug":"技术基础","permalink":"https://awk001.github.io/categories/%E6%8A%80%E6%9C%AF%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"程序员必备","slug":"程序员必备","permalink":"https://awk001.github.io/tags/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BF%85%E5%A4%87/"}]},{"title":"英语语法","slug":"英语","date":"2024-11-07T14:06:18.000Z","updated":"2025-02-24T15:20:39.083Z","comments":true,"path":"2024/11/07/英语/","permalink":"https://awk001.github.io/2024/11/07/%E8%8B%B1%E8%AF%AD/","excerpt":"","text":"英语语法一、动词实义动词及物动词（vt.）必须跟宾语；不及物动词（vi.）需要加介词后跟宾语 系动词：无实际意义，连接主语和表语 类型 单词 表状态 be 感官动词 look , smell , taste , sound , feel 表变化 become , get , turn , grow , fall 表保持 keep , stay , remain , stand 表表象 seem ， appear 表终止或结果 prove 助动词构成疑问、否定、时态和语态 be do &#x2F; did &#x2F; does Have &#x2F; has will 情态动词 表示说话人的主观态度 与实义动词&#x2F;系动词一起构成谓语 单词 含义 Can &#x2F; could 能够，会，可以，可能 May &#x2F; might 许可，可能性 Must &#x2F; have to 必须，不得不 Should &#x2F; ought to 应该 Would 将会，想要 need 需要 dare 敢","categories":[{"name":"课程学习","slug":"课程学习","permalink":"https://awk001.github.io/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"自我提升","slug":"自我提升","permalink":"https://awk001.github.io/tags/%E8%87%AA%E6%88%91%E6%8F%90%E5%8D%87/"}]},{"title":"Redis基于Windows系统的安装","slug":"Redis基于Windows系统的安装","date":"2024-10-27T14:01:18.000Z","updated":"2024-10-27T14:29:33.250Z","comments":true,"path":"2024/10/27/Redis基于Windows系统的安装/","permalink":"https://awk001.github.io/2024/10/27/Redis%E5%9F%BA%E4%BA%8EWindows%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AE%89%E8%A3%85/","excerpt":"","text":"一、Redis的下载Redis官网并不支持Windows格式下载所以我们去github上下载 链接：https://github.com/MSOpenTech/redis/releases 二、安装Redis 自定义存放位置。下载.zip格式的安装包，自定义一个位置，将压缩包的文件解压进去 开启服务。打开cmd切换到该目录下，执行命令redis-server redis.windows.conf直接使用 [!tip] 注意此时不能关闭cmd窗口、若关闭则Redis也关闭了 尝试客户端连接。这时候另启一个 cmd 窗口，切换到 redis 目录下运行: 1redis-cli.exe -h 127.0.0.1 -p 6379 设置键值对: 1set myKey abc 取出键值对: 1get myKey 退出: 123shutdown# 然后按 ctrl + c 就彻底退出了 三、系统服务加入Redis运行命令 1redis-server.exe --service-install redis.windows.conf --loglevel verbose 12345678#启动服务redis-server --service-start#停止服务redis-server –service-stop#卸载服务redis-server --service-uninstall 四、密码设置redis密码设置有两种方式，一种需要重启redis服务，一种不需要重启redis服务。 需要重启redis服务的设置方式即找到redis的配置文件—redis.conf文件，然后修改里面的requirepass，这个本来是注释起来了的，将注释去掉，并将后面对应的字段设置成自己想要的密码，保存退出。重启redis服务，即可。 不需要重启redis服务的密码设置方式这种相对简单，连接redis之后，通过命令设置，如下： 12config set requirepass 123456# 如此，便将密码设置成了123456 设置之后，可通过以下指令查看密码 1config get requirepass [!tip] 注意：通过命令行修改了密码之后，配置文件的requirepass字段后面的密码是不会随之修改的 附录：Redis配置文件样例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384# Redis配置文件样例# Note on units: when memory size is needed, it is possible to specifiy# it in the usual form of 1k 5GB 4M and so forth:## 1k =&gt; 1000 bytes# 1kb =&gt; 1024 bytes# 1m =&gt; 1000000 bytes# 1mb =&gt; 1024*1024 bytes# 1g =&gt; 1000000000 bytes# 1gb =&gt; 1024*1024*1024 bytes## units are case insensitive so 1GB 1Gb 1gB are all the same.# Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程# 启用守护进程后，Redis会把pid写到一个pidfile中，在/var/run/redis.pid#是否在后台运行；no：不是后台运行 daemonize yes #是否开启保护模式，默认开启。要是配置里没有指定bind和密码。开启该参数后，redis只会本地进行访问，拒绝外部访问。 protected-mode yes #redis的进程文件 pidfile /var/run/redis/redis-server.pid #redis监听的端口号。 port 6379#此参数确定了TCP连接中已完成队列(完成三次握手之后)的长度， #当然此值必须不大于Linux系统定义的/proc/sys/net/core/somaxconn值，默认是511，而Linux的默认参数值是128。#当系统并发量大并且客户端速度缓慢的时候，可以将这二个参数一起参考设定。#该内核参数默认值一般是128，对于负载很大的服务程序来说大大的不够。#一般会将它修改为2048或者更大。在/etc/sysctl.conf中添加:net.core.somaxconn = 2048，然后在终端中执行sysctl -p。 tcp-backlog 511 #指定 redis 只接收来自于该 IP 地址的请求，如果不进行设置，那么将处理所有请求 #bind 127.0.0.1 #bind 0.0.0.0 #配置unix socket来让redis支持监听本地连接。 # unixsocket /var/run/redis/redis.sock #配置unix socket使用文件的权限 # unixsocketperm 700 # 此参数为设置客户端空闲超过timeout，服务端会断开连接，为0则服务端不会主动断开连接，不能小于0。 timeout 0 #tcp keepalive参数。如果设置不为0，就使用配置tcp的SO_KEEPALIVE值，#使用keepalive有两个好处:检测挂掉的对端。降低中间设备出问题而导致网络看似连接却已经与对端端口的问题。#在Linux内核中，设置了keepalive，redis会定时给对端发送ack。检测到对端关闭需要两倍的设置值。 tcp-keepalive 0 #指定了服务端日志的级别。#级别包括：debug（很多信息，方便开发、测试），#verbose（许多有用的信息，但是没有debug级别信息多），#notice（适当的日志级别，适合生产环境），#warn（只有非常重要的信息）loglevel notice #指定了记录日志的文件。空字符串的话，日志会打印到标准输出设备。后台运行的redis标准输出是/dev/null。 logfile /var/log/redis/redis-server.log #是否打开记录syslog功能 # syslog-enabled no #syslog的标识符。 # syslog-ident redis #日志的来源、设备 #syslog-facility local0 #数据库的数量，默认使用的数据库是DB 0。#可以通过SELECT命令选择一个db databases 16 # redis是基于内存的数据库，可以通过设置该值定期写入磁盘。 # 注释掉“save”这一行配置项就可以让保存数据库功能失效 # 900秒（15分钟）内至少1个key值改变（则进行数据库保存--持久化） # 300秒（5分钟）内至少10个key值改变（则进行数据库保存--持久化） # 60秒（1分钟）内至少10000个key值改变（则进行数据库保存--持久化） save 900 1 save 300 10 save 60 10000 #当RDB持久化出现错误后，是否依然进行继续进行工作，#yes：不能进行工作，no：可以继续进行工作，#可以通过info中的rdb_last_bgsave_status了解RDB持久化是否有错误 stop-writes-on-bgsave-error yes #使用压缩rdb文件，rdb文件压缩使用LZF压缩算法，#yes：压缩，但是需要一些cpu的消耗。no：不压缩，需要更多的磁盘空间 rdbcompression yes #是否校验rdb文件。#从rdb格式的第五个版本开始，在rdb文件的末尾会带上CRC64的校验和。这跟有利于文件的容错性，但是在保存rdb文件的时候，会有大概10%的性能损耗，所以如果你追求高性能，可以关闭该配置。 rdbchecksum yes #rdb文件的名称 dbfilename dump.rdb #数据目录，数据库的写入会在这个目录。#rdb、aof文件也会写在这个目录 dir /data############### 主从复制 ############### #复制选项，slave复制对应的master。 # slaveof &lt;masterip&gt;&lt;masterport&gt;#如果master设置了requirepass，那么slave要连上master，需要有master的密码才行。masterauth就是用来配置master的密码，这样可以在连上master后进行认证。 # masterauth &lt;master-password&gt;#当从库同主机失去连接或者复制正在进行，从机库有两种运行方式：#1) 如果slave-serve-stale-data设置为yes(默认设置)，从库会继续响应客户端的请求。#2) 如果slave-serve-stale-data设置为no，#除去INFO和SLAVOF命令之外的任何请求都会返回一个错误”SYNC with master in progress”。 slave-serve-stale-data yes #作为从服务器，默认情况下是只读的（yes），可以修改成NO，用于写（不建议）。 slave-read-only yes #是否使用socket方式复制数据。#目前redis复制提供两种方式，disk和socket。#如果新的slave连上来或者重连的slave无法部分同步，就会执行全量同步，master会生成rdb文件。#有2种方式：#disk方式是master创建一个新的进程把rdb文件保存到磁盘，再把磁盘上的rdb文件传递给slave。#socket是master创建一个新的进程，直接把rdb文件以socket的方式发给slave。#disk方式的时候，当一个rdb保存的过程中，多个slave都能共享这个rdb文件。#socket的方式就的一个个slave顺序复制。在磁盘速度缓慢，网速快的情况下推荐用socket方式。 repl-diskless-sync no #diskless复制的延迟时间，防止设置为0。#一旦复制开始，节点不会再接收新slave的复制请求直到下一个rdb传输。#所以最好等待一段时间，等更多的slave连上来。 repl-diskless-sync-delay 5 #slave根据指定的时间间隔向服务器发送ping请求。#时间间隔可以通过 repl_ping_slave_period 来设置，默认10秒。 # repl-ping-slave-period 10 #复制连接超时时间。#master和slave都有超时时间的设置。master检测到slave上次发送的时间超过repl-timeout，即认为slave离线，清除该slave信息。#slave检测到上次和master交互的时间超过repl-timeout，则认为master离线。#需要注意的是repl-timeout需要设置一个比repl-ping-slave-period更大的值，不然会经常检测到超时。 # repl-timeout 60 #是否禁止复制tcp链接的tcp #nodelay参数，可传递yes或者no。默认是no，即使用tcp nodelay。#如果master设置了yes来禁止tcp nodelay设置，在把数据复制给slave的时候，会减少包的数量和更小的网络带宽。但是这也可能带来数据的延迟。#默认我们推荐更小的延迟，但是在数据量传输很大的场景下，建议选择yes。 repl-disable-tcp-nodelay no #复制缓冲区大小，#这是一个环形复制缓冲区，用来保存最新复制的命令。#这样在slave离线的时候，不需要完全复制master的数据，#如果可以执行部分同步，只需要把缓冲区的部分数据复制给slave，就能恢复正常复制状态。#缓冲区的大小越大，slave离线的时间可以更长，复制缓冲区只有在有slave连接的时候才分配内存。#没有slave的一段时间，内存会被释放出来，默认1m。 # repl-backlog-size 5mb #master没有slave一段时间会释放复制缓冲区的内存，#repl-backlog-ttl用来设置该时间长度。单位为秒。 # repl-backlog-ttl 3600 #当master不可用，Sentinel会根据slave的优先级选举一个master。#最低的优先级的slave，当选master。而配置成0，永远不会被选举。 slave-priority 100 #redis提供了可以让master停止写入的方式，#如果配置了min-slaves-to-write，健康的slave的个数小于N，mater就禁止写入。#master最少得有多少个健康的slave存活才能执行写命令。#这个配置虽然不能保证N个slave都一定能接收到master的写操作，但是能避免没有足够健康的slave的时候，master不能写入来避免数据丢失。#设置为0是关闭该功能。 # min-slaves-to-write 3 #延迟小于min-slaves-max-lag秒的slave才认为是健康的slave。 # min-slaves-max-lag 10 # 设置1或另一个设置为0禁用这个特性。 # Setting one or the other to 0 disables the feature. # By default min-slaves-to-write is set to 0 (feature disabled) and # min-slaves-max-lag is set to 10. ############### 安全相关 ############### #requirepass配置可以让用户使用AUTH命令来认证密码，才能使用其他命令。#这让redis可以使用在不受信任的网络中。为了保持向后的兼容性，可以注释该命令，因为大部分用户也不需要认证。#使用requirepass的时候需要注意，因为redis太快了，每秒可以认证15w次密码，简单的密码很容易被攻破，所以最好使用一个更复杂的密码。#注意只有密码没有用户名。 # requirepass foobared #把危险的命令给修改成其他名称。#比如CONFIG命令可以重命名为一个很难被猜到的命令，这样用户不能使用，而内部工具还能接着使用。 # rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52 #设置成一个空的值，可以禁止一个命令 # rename-command CONFIG &quot;&quot; ############### 进程限制相关 ############### # 设置能连上redis的最大客户端连接数量。默认是10000个客户端连接。#由于redis不区分连接是客户端连接还是内部打开文件或者和slave连接等，所以maxclients最小建议设置到32。#如果超过了maxclients，redis会给新的连接发送’max number of clients reached’，并关闭连接。 # maxclients 10000#redis配置的最大内存容量。当内存满了，需要配合maxmemory-policy策略进行处理。#注意slave的输出缓冲区是不计算在maxmemory内的。#所以为了防止主机内存使用完，建议设置的maxmemory需要更小一些。# maxmemory &lt;bytes&gt;#内存容量超过maxmemory后的处理策略。 #volatile-lru：利用LRU算法移除设置过过期时间的key。 #volatile-random：随机移除设置过过期时间的key。 #volatile-ttl：移除即将过期的key，根据最近过期时间来删除（辅以TTL） #allkeys-lru：利用LRU算法移除任何key。 #allkeys-random：随机移除任何key。 #noeviction：不移除任何key，只是返回一个写错误。 #上面的这些驱逐策略，如果redis没有合适的key驱逐，对于写命令，还是会返回错误。#redis将不再接收写请求，只接收get请求。#写命令包括：set setnx setex append incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby getset mset msetnx exec sort。 # maxmemory-policy noeviction #lru检测的样本数。#使用lru或者ttl淘汰算法，从需要淘汰的列表中随机选择sample个key，选出闲置时间最长的key移除。 # maxmemory-samples 5 ############### APPEND ONLY 持久化方式 ############### #默认redis使用的是rdb方式持久化，这种方式在许多应用中已经足够用了。#但是redis如果中途宕机，会导致可能有几分钟的数据丢失，根据save来策略进行持久化，Append Only File是另一种持久化方式，可以提供更好的持久化特性。#Redis会把每次写入的数据在接收后都写入 appendonly.aof 文件，每次启动时Redis都会先把这个文件的数据读入内存里，先忽略RDB文件。 appendonly no #aof文件名 appendfilename &quot;appendonly.aof&quot; #aof持久化策略的配置 #no表示不执行fsync，由操作系统保证数据同步到磁盘，速度最快。 #always表示每次写入都执行fsync，以保证数据同步到磁盘。 #everysec表示每秒执行一次fsync，可能会导致丢失这1s数据。 appendfsync everysec # 在aof重写或者写入rdb文件的时候，会执行大量IO，#此时对于everysec和always的aof模式来说，执行fsync会造成阻塞过长时间，no-appendfsync-on-rewrite字段设置为默认设置为no，是最安全的方式，不会丢失数据，但是要忍受阻塞的问题。#如果对延迟要求很高的应用，这个字段可以设置为yes，，设置为yes表示rewrite期间对新写操作不fsync,暂时存在内存中,不会造成阻塞的问题（因为没有磁盘竞争），等rewrite完成后再写入，这个时候redis会丢失数据。#Linux的默认fsync策略是30秒。可能丢失30秒数据。#因此，如果应用系统无法忍受延迟，而可以容忍少量的数据丢失，则设置为yes。#如果应用系统无法忍受数据丢失，则设置为no。 no-appendfsync-on-rewrite no #aof自动重写配置。#当目前aof文件大小超过上一次重写的aof文件大小的百分之多少进行重写，#即当aof文件增长到一定大小的时候Redis能够调用bgrewriteaof对日志文件进行重写。#当前AOF文件大小是上次日志重写得到AOF文件大小的二倍（设置为100）时，自动启动新的日志重写过程。 auto-aof-rewrite-percentage 100 #设置允许重写的最小aof文件大小，避免了达到约定百分比但尺寸仍然很小的情况还要重写 auto-aof-rewrite-min-size 64mb #aof文件可能在尾部是不完整的，当redis启动的时候，aof文件的数据被载入内存。#重启可能发生在redis所在的主机操作系统宕机后，尤其在ext4文件系统没有加上data=ordered选项（redis宕机或者异常终止不会造成尾部不完整现象。）出现这种现象，#可以选择让redis退出，或者导入尽可能多的数据。#如果选择的是yes，当截断的aof文件被导入的时候，会自动发布一个log给客户端然后load。#如果是no，用户必须手动redis-check-aof修复AOF文件才可以。 aof-load-truncated yes ############### LUA SCRIPTING ############### # 如果达到最大时间限制（毫秒），redis会记个log，然后返回error。#当一个脚本超过了最大时限。只有SCRIPT KILL和SHUTDOWN NOSAVE可以用。#第一个可以杀没有调write命令的东西。要是已经调用了write，只能用第二个命令杀。lua-time-limit 5000 ############### 集群相关 ############### #集群开关，默认是不开启集群模式。 # cluster-enabled yes #集群配置文件的名称，每个节点都有一个集群相关的配置文件，持久化保存集群的信息。#这个文件并不需要手动配置，这个配置文件有Redis生成并更新，每个Redis集群节点需要一个单独的配置文件，请确保与实例运行的系统中配置文件名称不冲突 # cluster-config-file nodes-6379.conf #节点互连超时的阀值。集群节点超时毫秒数 # cluster-node-timeout 15000 #在进行故障转移的时候，全部slave都会请求申请为master，但是有些slave可能与master断开连接一段时间了，导致数据过于陈旧，这样的slave不应该被提升为master。#该参数就是用来判断slave节点与master断线的时间是否过长。#判断方法是： #比较slave断开连接的时间和(node-timeout * slave-validity-factor) + repl-ping-slave-period #如果节点超时时间为三十秒, 并且slave-validity-factor为10,假设默认的repl-ping-slave-period是10秒，即如果超过310秒slave将不会尝试进行故障转移 # cluster-slave-validity-factor 10 #master的slave数量大于该值，slave才能迁移到其他孤立master上，#如这个参数若被设为2，那么只有当一个主节点拥有2 个可工作的从节点时，它的一个从节点会尝试迁移。 # cluster-migration-barrier 1 #默认情况下，集群全部的slot有节点负责，集群状态才为ok，才能提供服务。设置为no，可以在slot没有全部分配的时候提供服务。不建议打开该配置。 # cluster-require-full-coverage yes ############### SLOW LOG 慢查询日志 ############### ###slog log是用来记录redis运行中执行比较慢的命令耗时。#当命令的执行超过了指定时间，就记录在slow log中，slog log保存在内存中，所以没有IO操作。# #执行时间比slowlog-log-slower-than大的请求记录到slowlog里面，单位是微秒，所以1000000就是1秒。#注意，负数时间会禁用慢查询日志，而0则会强制记录所有命令。 slowlog-log-slower-than 10000 #慢查询日志长度。当一个新的命令被写进日志的时候，最老的那个记录会被删掉。#这个长度没有限制。只要有足够的内存就行。#你可以通过 SLOWLOG RESET 来释放内存。 slowlog-max-len 128 ############### 延迟监控 ############### #延迟监控功能是用来监控redis中执行比较缓慢的一些操作，用LATENCY打印redis实例在跑命令时的耗时图表。#只记录大于等于下边设置的值的操作。0的话，就是关闭监视。默认延迟监控功能是关闭的，#如果你需要打开，也可以通过CONFIG SET命令动态设置。 latency-monitor-threshold 0 ############### EVENT NOTIFICATION 订阅通知 ############### #键空间通知使得客户端可以通过订阅频道或模式，来接收那些以某种方式改动了 Redis 数据集的事件。#因为开启键空间通知功能需要消耗一些 CPU ，所以在默认配置下，该功能处于关闭状态。 #notify-keyspace-events 的参数可以是以下字符的任意组合，#它指定了服务器该发送哪些类型的通知： ##K 键空间通知，所有通知以 __keyspace@__ 为前缀 ##E 键事件通知，所有通知以 __keyevent@__ 为前缀 ##g DEL 、 EXPIRE 、 RENAME 等类型无关的通用命令的通知 ##$ 字符串命令的通知 ##l 列表命令的通知 ##s 集合命令的通知##h 哈希命令的通知 ##z 有序集合命令的通知 ##x 过期事件：每当有过期键被删除时发送 ##e 驱逐(evict)事件：每当有键因为 maxmemory 政策而被删除时发送 ##A 参数 g$lshzxe 的别名 #输入的参数中至少要有一个 K 或者 E，否则的话，不管其余的参数是什么，都不会有任何 通知被分发。详细使用可以参考http://redis.io/topics/notifications notify-keyspace-events &quot;&quot; ############### ADVANCED CONFIG 高级配置 ############### #数据量小于等于hash-max-ziplist-entries的用ziplist，大于hash-max-ziplist-entries用hash hash-max-ziplist-entries 512 #value大小小于等于hash-max-ziplist-value的用ziplist，大于hash-max-ziplist-value用hash。 hash-max-ziplist-value 64#数据量小于等于list-max-ziplist-entries用ziplist，大于list-max-ziplist-entries用list。 list-max-ziplist-entries 512 #value大小小于等于list-max-ziplist-value的用ziplist，大于list-max-ziplist-value用list。list-max-ziplist-value 64 #数据量小于等于set-max-intset-entries用iniset，大于set-max-intset-entries用set。 set-max-intset-entries 512 #数据量小于等于zset-max-ziplist-entries用ziplist，大于zset-max-ziplist-entries用zset。 zset-max-ziplist-entries 128 #value大小小于等于zset-max-ziplist-value用ziplist，大于zset-max-ziplist-value用zset。 zset-max-ziplist-value 64 #value大小小于等于hll-sparse-max-bytes使用稀疏数据结构（sparse），大于hll-sparse-max-bytes使用稠密的数据结构（dense）。#一个比16000大的value是几乎没用的，建议的value大概为3000。#如果对CPU要求不高，对空间要求较高的，建议设置到10000左右。 hll-sparse-max-bytes 3000 #Redis将在每100毫秒时使用1毫秒的CPU时间来对redis的hash表进行重新hash，可以降低内存的使用。#当你的使用场景中，有非常严格的实时性需要，不能够接受Redis时不时的对请求有2毫秒的延迟的话，把这项配置为no。#如果没有这么严格的实时性要求，可以设置为yes，以便能够尽可能快的释放内存。 activerehashing yes ##对客户端输出缓冲进行限制可以强迫那些不从服务器读取数据的客户端断开连接，用来强制关闭传输缓慢的客户端。 #对于normal client，第一个0表示取消hard limit，第二个0和第三个0表示取消soft limit，normal client默认取消限制，因为如果没有寻问，他们是不会接收数据的。 client-output-buffer-limit normal 0 0 0 #对于slave client和MONITER client，如果client-output-buffer一旦超过256mb，又或者超过64mb持续60秒，那么服务器就会立即断开客户端连接。 client-output-buffer-limit slave 256mb 64mb 60 #对于pubsub client，如果client-output-buffer一旦超过32mb，又或者超过8mb持续60秒，那么服务器就会立即断开客户端连接。 client-output-buffer-limit pubsub 32mb 8mb 60 #redis执行任务的频率为1s除以hz。 hz 10 #在aof重写的时候，如果打开了aof-rewrite-incremental-fsync开关，系统会每32MB执行一次fsync。#这对于把文件写入磁盘是有帮助的，可以避免过大的延迟峰值。 aof-rewrite-incremental-fsync yes","categories":[{"name":"技术基础","slug":"技术基础","permalink":"https://awk001.github.io/categories/%E6%8A%80%E6%9C%AF%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"程序员必备","slug":"程序员必备","permalink":"https://awk001.github.io/tags/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BF%85%E5%A4%87/"}]},{"title":"NodeJS基于Win系统的安装与配置","slug":"NodeJS基于Windows系统的安装与配置","date":"2024-10-17T11:06:18.000Z","updated":"2024-10-21T16:31:33.325Z","comments":true,"path":"2024/10/17/NodeJS基于Windows系统的安装与配置/","permalink":"https://awk001.github.io/2024/10/17/NodeJS%E5%9F%BA%E4%BA%8EWindows%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/","excerpt":"","text":"一、NodeJS的安装1.1 下载NodeJSNode.js 官方链接 (nodejs.org) 1.2 安装NodeJS下载完成后，双击安装包，开始安装，一直点next即可，安装路径默认在C:\\Program Files下，也可以自定义修改，如D:\\Programs\\NodeJS 目前版本Node.js v20.18.0来说，使用.exe直接安装后，会默认将NodeJS的安装路径存储在环境变量中。 打开cmd窗口，查看node版本，当前版本同时也安装了Npm： 12node -vnpm -v 二、Npm包的配置优化2.1 npm下载加速默认的npm下载加速很慢，使用时可以使用第三方源加速使用 12# 淘宝镜像源npm config set registry https://registry.npmmirror.com 2.2 修改全局依赖包下载路径默认情况下，我们在执行npm install -g XXXX下载全局包时，这个包的默认存放路径位C:\\Users\\用户名\\AppData\\Roaming\\npm\\node_modules下，可以通过CMD指令npm root -g查看 1C:\\Users\\Administer\\AppData\\Roaming\\npm\\node_modules 但是有时候我们不想让全局包放在这里，我们可以自定义存放目录,在CMD窗口执行以下两条命令修改默认路径： 123# 在NodeJS的安装目录下新增文件夹node_global和node_cachenpm config set prefix &quot;D:\\Programs\\NodeJS\\node_global&quot;npm config set cache &quot;D:\\Programs\\NodeJS\\node_cache&quot; 2.3 配置环境变量由于修改了全局包的下载路径，那么npm下载的全局包就会存放在D:\\Programs\\NodeJS\\node_global\\node_modules，而其对应的cmd指令会存放在D:\\Programs\\NodeJS\\node_global 我全局安装一个hexo-cli用来搭建博客 1npm install -g hexo-cli 安装完成后的依赖包：D:\\Programs\\NodeJS\\node_global\\ 已经安装的依赖程序文件夹：D:\\Programs\\NodeJS\\node_global\\&#x3D;&#x3D;node_modules\\hexo-cli&#x3D;&#x3D; 那么此时我们想使用hexo指令时就必须是在已经修改的全局依赖包的路径下，将其路径D:\\Programs\\NodeJS\\node_global\\&#x3D;&#x3D;node_modules&#x3D;&#x3D;添加到系统变量即可。 OK！大功告成！","categories":[{"name":"技术基础","slug":"技术基础","permalink":"https://awk001.github.io/categories/%E6%8A%80%E6%9C%AF%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"程序员必备","slug":"程序员必备","permalink":"https://awk001.github.io/tags/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BF%85%E5%A4%87/"}]}],"categories":[{"name":"Java框架","slug":"Java框架","permalink":"https://awk001.github.io/categories/Java%E6%A1%86%E6%9E%B6/"},{"name":"技术基础","slug":"技术基础","permalink":"https://awk001.github.io/categories/%E6%8A%80%E6%9C%AF%E5%9F%BA%E7%A1%80/"},{"name":"课程学习","slug":"课程学习","permalink":"https://awk001.github.io/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"自我提升","slug":"自我提升","permalink":"https://awk001.github.io/tags/%E8%87%AA%E6%88%91%E6%8F%90%E5%8D%87/"},{"name":"程序员必备","slug":"程序员必备","permalink":"https://awk001.github.io/tags/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BF%85%E5%A4%87/"}]}